{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evHVxwk2JA-3"
   },
   "source": [
    "# <p style=\"text-align: center;\">MIS 382N: Advanced Machine Learning</p>\n",
    "# <p style=\"text-align: center;\">Homework 1</p>\n",
    "## <p style=\"text-align: center;\">Total points: 55</p>\n",
    "## <p style=\"text-align: center;\">Due: Wednesday, Sep 8 submitted via Canvas by 11:59 pm</p>\n",
    "\n",
    "Your homework should be written in a **Jupyter notebook**. Please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting. (%matplotlib inline)\n",
    "\n",
    "**Note: Notebooks MUST have the images embedded in them. There will be no regrades if attached images do not render in the notebook. Please re download from canvas after submission and make sure all attached images render without errors. (Hint: Image module from IPython.display)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWWU_gOSLEEv"
   },
   "source": [
    "# Question 1: MLOps (10 pts)\n",
    "Read this [article](https://towardsdatascience.com/what-is-mlops-everything-you-must-know-to-get-started-523f2d0b8bd8) \"What is MLOps — Everything You Must Know to Get Started\", which gives a quick walkthrough of the machine learning development lifecycle and explains how MLOps come into play, or watch this [video](https://www.youtube.com/watch?v=06-AZXmwHjo) which you may find interesting.\n",
    "\n",
    "1. (**4 pts**) Use your own words to describe what MLOps is, and what challenges MLOps address. Limit your answer to one paragraph.\n",
    "\n",
    "2. (**6 pts**) Describe what the main phases in MLOps are. Your answer should be 2-3 paragraphs.\n",
    "\n",
    "\n",
    "## Answer:\n",
    "\n",
    "1. MLOps can be thought of as a discipline that is trying to combine and unify Machine Learning code development and Machine Learning deployment. In traditional software development process, the software engineers handled the software development part and DevOps handles that deployment part. The traditional software development porcess doesn't work in case of ML models, because ML models are built based on some assumption and data. Therefore, these ML models can become obselete with time as the data is changes and assumptions are found to be wrong. Thus we need to keep constanly updating ML models for data change and model changes. Because of the need of constant change, the traditional software develeopment process doesn't work. With the presence of MLOps, it is much more easier and structured to update these models without breaking the system. This helps in delivering high performance ML models \n",
    "<br>\n",
    "<br>\n",
    "2. MLOps phases can be divided into 4 broad categories - Scope project, Collect data, Train model, and Deploy model. The busienss people (usually product managers or Subject Matter Experts) define the business objectives and KPIs(Key Performing Indicator) for the ML project. Data Engineers then collect the relevant data for the business problem. The quality and quantity of data collected is very critical for the whole pipeline. If the data quantity is low, the data quality (or labelling) should be very high for high perfromance. If data quantity is high, moderate data quality might be OK.\n",
    "<br>\n",
    "Based business objective and data collected, data is preprared for ML models. The preprocessing can include removing outliers, performing feature engineering to create new features. After this, relevant ML model (with specific hyperparameters) is chosen by the Data Scientist. It is very important that model and results achieved by data scientist should be reproducable and scalable i.e. similar output performance should be possible when model is deployed on cloud.\n",
    "<br>\n",
    "The ML model is deloyed onto relevant system based on requirement. After depolyment, the most important part is monitoring the model - is the model performing and is it meeting the business objective? Based on answer to this question, the model and data to the model is updated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wusA9L1LmUMH"
   },
   "source": [
    "# Question 2: Applications of Machine Learning (5 pts)\n",
    "Read this [article](https://builtin.com/data-science/data-science-applications-examples) \"17 Data Science Applications & Examples\" and pick one of the data science systems used by various organizations according to this blog. \n",
    "\n",
    "For this system you have chosen, answer the following questions. Please limit your answer to one paragraph:\n",
    "\n",
    "1. What kind of machine learning problem is involved (e.g. classification, regression, clustering, outlier detection,...) in this system?\n",
    "2. Speculate on what kind of data may be needed and how the results can be useful to the organization.\n",
    "3. What do you think are the ethical implications of using machine learning in a domain like this?\n",
    "\n",
    "## Answer:\n",
    "\n",
    "Data science system - LYNA, for detection of breast cancer.<br>\n",
    "This system involves solving a **classification** problem. The system has to classify if a patient has breast cancer. This system probably uses various kinds of input data - 1. tabular data that conatins information such as age, gender, income 2. text data which contains all the medical history of the patient 3. image data which contains pictures related to medical tests performed to check for the breast cancer. This kind of system can help medical organization in identifying high risk patients for breast cancer. The organization will be able to treat the cancer at an early stage thus helping the patient and the organization. The data science system has some risks too - 1. What is the risk of wrongly classifying non-cancer patient as having cancer? Patient might unwilling forced to pay for medical tests 2. What is the risk of wrongly classifying cancer patient as NOT having cancer? If the organization overly relies on this system and misses some patient, then, in worst case scenario, it can result in deaths 3. Is it ethical to mine the data without getting proper consent from all the patients?   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2w8za9lLmVO7"
   },
   "source": [
    "# Question 3: Simpson's Paradox (10 pts)\n",
    "A data scientist should be careful about drawing unwarranted conclusions about any data that is presented. One of the 'gotchas' that can happen even in apparently very simple tabular summaries, is called Simpson's paradox.\n",
    "\n",
    "Read this [article](https://www.covid-datascience.com/post/israeli-data-how-can-efficacy-vs-severe-disease-be-strong-when-60-of-hospitalized-are-vaccinated), which explains why the computed efficacy of the Pfizer vaccine is misleadingly low (67.5%) when you lump all people together, but once you stratify people by age (which is the right thing to do), you get much higher efficacy numbers.\n",
    "\n",
    "1.(**5 pts**) Explain in your own words what Simpson's paradox is, and how this 'paradox' can happen in real data.\n",
    "\n",
    "2.(**5 pts**) Find and mention another example of Simpson's paradox (but not any of the 3 examples given in the Wikipedia entry for 'Simpson's paradox'), state why the paradox appeared in your chosen example. Also give a reference (URL) to your source for the chosen example.\n",
    "\n",
    "## Answer:\n",
    "\n",
    "1. Simpson' paradox - A pattern or trend in data that reverses or disappears when all the data is combined. If let's say, we are trying to understand relationship between 2 variables, then a 3rd variable, which is confounding variable, can cause the relationship between the varaibles be distorted. For e.g. - If let's say two variables have negative corelation, then a confounding varible can cause relation to reverse and can lead us to believe that the variables have positive correlation. By 'controlling' for this confounding variable, we can remove effect of this confounding variable. For e.g. - In case of Pfizer vaccine, the confounding variable was age. Combinig the data indicated low efficacy but stratifying for age, showed drastically high efficacy. Stratifying by age 'controlled' for 2 things - 1. Disparity in vaccination rate by age 2. Disparity in rate of severe cases (rate of severe cases was higher in 50+ compared to less than 50). By 'controlling' for age or by spiliting the data by age, we were able to understand the 'true' relationship between vaccination and severe case rate. These confounding variables can be present in any physical system. It's the reponsibility of the statistician/ data scientist to figure this \"relation corruption\".  \n",
    "<br><br>\n",
    "2. US median wage decline - [link](https://blog.revolutionanalytics.com/2013/07/a-great-example-of-simpsons-paradox.html)\n",
    "<br>Total: +0.9%\n",
    "<br>High School Dropouts: -7.9%\n",
    "<br>High School Graduates, No College: -4.7%\n",
    "<br>Some College: -7.6%\n",
    "<br>Bachelor’s or Higher: -1.2%\n",
    "<br>Overall the median wage in US has increased by 1%(adjusting for inflation). The data is broken down on the basis of eductaion level - high school droputs, high school graduate, some college education, and Bachelor and other high degree. It was found that median wage for each group has dropped. Thus creating a pradox - how can median increase overall but drop for each subgroup? Explanation - By looking at proportions of college graduates over time and their income, we can figure out 2 things - 1. The proportion of college graduates has increased 2. The decrease in wage of college graduates is much less than compared to high school dropouts. This change increase in proportion of group which has much lower decrease rate led to an overall impact in which the median statistic incerased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gth0D8jiMBSe"
   },
   "source": [
    "# Question 4: Ridge and Lasso Regression (30 pts)\n",
    "\n",
    "Download the dataset **Admission.csv** from Canvas and use the following codes to import the Admission dataset in Python. \n",
    "\n",
    "There are 7 features in the dataset:\n",
    "\n",
    "1. GRE score\n",
    "2. TOEFL score\n",
    "3. University Rating\n",
    "4. SOP(Statement of Purpose)\n",
    "5. LOR(Letter of Recommendation)\n",
    "6. CGPA\n",
    "7. Research\n",
    "\n",
    "And the target is **Chance of Admission**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFazlpLgGpAa"
   },
   "outputs": [],
   "source": [
    "# Only use this code block if you are using Google Colab.\n",
    "# If you are using Jupyter Notebook, please ignore this code block. You can directly upload the file to your Jupyter Notebook file systems.\n",
    "from google.colab import files\n",
    "\n",
    "## It will prompt you to select a local file. Click on “Choose Files” then select and upload the file. \n",
    "## Wait for the file to be 100% uploaded. You should see the name of the file once Colab has uploaded it.\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xsPaOOehGuU6"
   },
   "outputs": [],
   "source": [
    "# Codes below will work for both Google Colab and Jupyter Notebook.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "## Load the dataset into pandas DataFrame\n",
    "df = pd.read_csv('Admission.csv', index_col=0)\n",
    "df = df.replace([np.inf, -np.inf], np.nan) # \n",
    "df = df.fillna(0) # Replace all the NaN values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PmMz72U6Gv-z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GRE_Score', 'TOEFL_Score', 'University_Rating', 'SOP', 'LOR ', 'CGPA',\n",
       "       'Research', 'Chance_of_Admit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns # Show you all the columns in this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CyZN-yFfGxlt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE_Score</th>\n",
       "      <th>TOEFL_Score</th>\n",
       "      <th>University_Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance_of_Admit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serial No.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            GRE_Score  TOEFL_Score  University_Rating  SOP  LOR   CGPA  \\\n",
       "Serial No.                                                               \n",
       "1                 337          118                  4  4.5   4.5  9.65   \n",
       "2                 324          107                  4  4.0   4.5  8.87   \n",
       "3                 316          104                  3  3.0   3.5  8.00   \n",
       "4                 322          110                  3  3.5   2.5  8.67   \n",
       "5                 314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "            Research  Chance_of_Admit  \n",
       "Serial No.                             \n",
       "1                  1             0.92  \n",
       "2                  1             0.76  \n",
       "3                  1             0.72  \n",
       "4                  1             0.80  \n",
       "5                  0             0.65  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # Show you the first 5 rows in this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "S3TfR0i4G2rO"
   },
   "outputs": [],
   "source": [
    "y = df['Chance_of_Admit'] # The column named Chance_of_Admit is used as the target, and we store it in y\n",
    "X = df.drop(['Chance_of_Admit'], axis=1) # We keep the remaining columns as the features, and store them in x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKq1KERxJw9y"
   },
   "source": [
    "1)(**2 pts**) Split the data into a training set(75% of data) and a test set(25% of data), using the [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function with random_state = 50. Then scale the data (not including target) so that each of the independent variables would have zero mean and unit variance. You can use the [sklearn.preprocessing.scale](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html) function for this. Print the first 5 rows of the training set after scaling.\n",
    "\n",
    "2)(**5 pts**) Use [sklearn.linear_model.Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) and [sklearn.linear_model.Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) classes to do a **5-fold** cross validation using sklearn's KFold. For the sweep of the regularization parameter, we will look at a grid of values ranging from α=10^10 to α=10^−6. In Python, you can consider this range of values as follows: alpha = 10**numpy.linspace(6,-6,100) \n",
    "so that you can generate 100 uniform values between -6 to 6 as power series.\n",
    "\n",
    "Fit the 2 regression models with scaled data and report the best chosen **α** based on cross validation as well as the corresponding scoring metric. The cross validation should happen on your training data using **MSE** as the scoring metric.\n",
    "\n",
    "3)(**5 pts**) Run ridge and lasso regression for all of the **α** specified above (on training data), and plot the coefficients learned for each of them - there should be one plot each for lasso and ridge, so a total of two plots; different features' weights of each model should be on the same plot with different colors (3pts). \n",
    "\n",
    "What do you qualitatively observe when the value of the regularization parameter changes (2pts)? \n",
    "\n",
    "4)(**3 pts**) Take the exponential of Y_train as the target, and fit the 2 regression models again. Report the best chosen **α** based on cross validation as well as the corresponding scoring metric. Compare the results of using the original target with the results of using the exponential of the target. What do you observe? \n",
    "\n",
    "5)(**5 pts**) Similarly, use [sklearn.linear_model.ElasticNet](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html) to do linear regression with different **α** values, and plot the coefficients learned for each of them (2pts). Observe the plot, then explain the pros and cons of ridge, lasso and Elastic Net models (3pts).\n",
    "\n",
    "\n",
    "6)(**5 pts**) Run the following three regression models with **MSE** loss on the training data: \n",
    "\n",
    "a. linear regression without regularization (1pts)\n",
    "\n",
    "b. linear regression with ridge regularization (2pts)\n",
    "\n",
    "c. linear regression with lasso regularization (2pts)\n",
    "\n",
    "For part (b) and (c), use only the best regularization parameters. Report the MSE and R<sup>2</sup> on the test data for each model.\n",
    "\n",
    "7)(**5 pts**) Train the 3 models and report the metrics with the original data without scaling (3pts). \n",
    "\n",
    "Why do we need to scale the data before regularization (2pts)? \n",
    "\n",
    "## Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.52725374,  2.0917706 ,  1.61594354,  0.63150829,  1.72829095,\n",
       "         2.11370277,  0.90453403],\n",
       "       [ 0.74180896,  0.46308859, -0.9310778 , -0.35266047, -1.04140609,\n",
       "         0.29488827,  0.90453403],\n",
       "       [ 0.56726568,  0.13735218,  1.61594354,  0.63150829,  0.62041214,\n",
       "         0.26211684,  0.90453403],\n",
       "       [-0.39272239, -0.51412062, -0.08207069,  0.13942391,  0.62041214,\n",
       "        -0.80295471, -1.1055416 ],\n",
       "       [ 0.47999403,  0.78882499,  0.76693642,  1.12359267,  1.17435154,\n",
       "         1.11417408,  0.90453403]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalar = StandardScaler()\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, \n",
    "                                                    train_size=.75,\n",
    "                                                    random_state=50)\n",
    "\n",
    "scaled_train_X = scalar.fit_transform(train_X)\n",
    "scaled_test_X = scalar.fit_transform(test_X)\n",
    "\n",
    "scaled_train_X[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso acheived lowest MSE of  0.004098425318055381  for  0.001072267222010321  alpha\n",
      "Ridge acheived lowest MSE of  0.00411801388424071  for  4.641588833612772  alpha\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "scorer = make_scorer(mean_squared_error)\n",
    "\n",
    "alphas = 10**np.linspace(6,-6,100)\n",
    "best_accruacy_lasso = np.inf\n",
    "best_alpha_lasso = None\n",
    "best_accruacy_ridge = np.inf\n",
    "best_alpha_ridge = None\n",
    "\n",
    "for a in alphas:\n",
    "    lasso = Lasso(alpha = a)\n",
    "    scores = cross_val_score(lasso, scaled_train_X, train_y, cv = 5, scoring = scorer)\n",
    "    if(np.mean(scores) < best_accruacy_lasso):\n",
    "        best_accruacy_lasso = np.mean(scores)\n",
    "        best_alpha_lasso = a\n",
    "    \n",
    "    ridge = Ridge(alpha = a)\n",
    "    scores = cross_val_score(ridge, scaled_train_X, train_y, cv = 5, scoring = scorer)\n",
    "    if(np.mean(scores) < best_accruacy_ridge):\n",
    "        best_accruacy_ridge = np.mean(scores)\n",
    "        best_alpha_ridge = a\n",
    "    \n",
    "print(\"Lasso acheived lowest MSE of \", best_accruacy_lasso, \" for \", best_alpha_lasso, \" alpha\")\n",
    "print(\"Ridge acheived lowest MSE of \", best_accruacy_ridge, \" for \", best_alpha_ridge, \" alpha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAAFWCAYAAABaRogPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAycUlEQVR4nO3debhkZXXv8e+PRgQRgkMbERAxooheQWwRxThrAI0YYxTUoMQEuUoUk2suMYNTkpvRKAmBkIBKHHDWVlHUqBhUlAYRRcS0IKEZtEEEBGRy3T/2PlB9+tQ5ddqza9ehvp/nqYfaQ9W7qji1eu13v/vdqSokSZK0tDbrOwBJkqQ7I4ssSZKkDlhkSZIkdcAiS5IkqQMWWZIkSR2wyJIkSeqARZY2WZKfJnngPNt/kORpS9TWyO+1lO1K2jRJjkvyZ/NsryQPGmdMs9o/L8mT5tn+xSS/u0RtjfxeS9mu+meR1aPlXgxU1d2r6kKAJO9I8hd9x7TUktwzyUeSXJ/k4iQvXGD/1yS5Isk1SU5MctdR3ivJFkk+2P5N1HzJX5oE7d/qje3B1hVtDrj7zPaqOryq3txnjPOpqodV1RcBkrwhybt6Dqkzbe5Zn+T0BfZbmeQ9SX6S5Ook7x7lvZI8OMnH2vU/TnJqkod08VmWG4ssaX7HADcDvwy8CDg2ycPm2jHJrwFHAU8FHgA8EHjjIt7rdODFwBVL+xGkzvx6Vd0d2BN4JPDH/YajIf4GOH+E/T5Mk392Bu4D/P2I77UdsBp4CE1++zrwsU2M9U7FImsCJblHkk+0RwVXt893HNj+0iQXJrkuyUVJXtSuf1CS09pelCuTvG/gNY9Lcma77cwkjxvS9qFJPj6wvDbJ+weWL0myZ/u82jYPoyka/qg9qv34wFvumeTctt33JdlySLu/kuTzSa5qY393ku2G7PuGttfnfe13cHaSPWbtNme7C323s9rZGvhN4M+q6qdVdTpNIvntufYHXgKcUFXnVdXVwJuBl47yXlV1c1W9tV1/25D3lyZSVV0BnEpTbAEb924neW2Sy5NcluR3Bl+f5F5JPp7k2jY//cWsnpLdkny27SW5IMnz54ojyZOTfGtg+XNJvj6wfHqS57TPf5DkaUn2A14HvKDNX98ceMudk3y5zTOfSXLvIe0uJq+8tH3Pf2rz03eTPHXWbkPbTfKB3NFb/qVhB30D+z8WeDjw9gX2ewawE/Daqrqmqm6pqm+M8l5V9fWqOqGqflxVtwD/CDwkyb3ma3MaWGRNps1o/oh3Bu4P3Aj8M9z+j/XRwP5VtQ3wOOCc9nVvBj4D3APYEfin9jX3BD7Zvu5ewFuATw75AZwG/GqSzZJsD9wF2Ld9nwcCdwfOHXxBVR0PvBv42/YU4q8PbH4+sB+wC/AI2qJjDgH+H3A/4KE0P/Y3DP2G4EDgA8A9gfcAH01ylxHaHfrdzuHBwG1V9b2Bdd8EhiW1h7XbB/f95fZ7Xux7SctGW1DsD6wdsn0/4P8ATwd2BWYPkzgGuB64L83ByksGXrs18Fma3/l9gIOBfxlSXHwVeFCSeyfZnKYg2DHJNkm2Ah4F/NfgC6rq08BfAe9r89fgAdsLgUPbdrdoP8NcFpNXAB4DXAjcG3g98OE2T4/S7qdovsP7AGfT5N45JVlB890eASx0D719gAuAd7YHu2cmeeImvtcTgCuq6qoF9rvTs8iaQFV1VVV9qKpuqKrrgL8Enjiwy8+BhyfZqqour6rz2vW30PzI71dVP2t7RQCeCfx3Vf1HVd1aVe8FvgsMFkMzbV8IXEdzRPpEmqPTS5Ps1i7/V1X9fBEf5+iquqyqfgx8nIEj3Vntrq2qz1bVTVW1nqYQfOJc+7bOqqoPtkdNbwG2pEkS87Y7wnc76O7ANbPWXQNsM+L+M8+32YT3kpaDjya5DrgE+BFNwTCX5wNvr6pvV9X1DBxAtf94/ybw+vZ3+R3gnQOvfRbwg6p6e5u/zgY+BDxvdiNV9TNgDc0/8qtoDghPpzlQ3IcmDy7mH/63V9X3qupG4P0Mz1+LySvQfFdvbXuL3kdT3DxzlHar6sSquq6qbqL5HvdI8ktD2nkV8LWqOmuEz7oj8AzgCzTF7j8AHxvoRRvpvdqC+xjgD0Zo807PImsCJblbkn9NMzj6WuBLwHZJVrQJ6gXA4cDlST7ZFkAAf0TTI/T1NFfOzHTJ3w+4eFYzFwM7DAnhNOBJNInqNOCLNAnjie3yYgyOL7qBptjYSJL7JDk5yaXtZ34XzVHeMJfMPGmLvnU0n3Peduf7budo46fAtrPWbUtThM5l9v4zz6/bhPeSloPntD3qTwJ2Y/hv9n4M/GbZMB+tBDaftX3w+c7AY9IMxv5Jkp/QDE+475C2+shfi8krAJdW1WBv0MWMlr9WJPnrJN9v2/lBu89G33uS+9EURn8y9NNt6EaaYvaEtvg7meb/w76jvleSlTRnU/6lPZifehZZk+kPaQYQPqaqtqVJFtAUUFTVqVX1dGB7mh6pf2vXX1FVv1dV9wNeTtOl/iDgMppENej+wKVD2p9JUr/aPj+NhZPUQt3HC/l/7Xs8ov3ML6b9vEPsNPMkyWY0R2GXjdDOvN/tLN8DNk+y68C6PYDz5tiXdv0es/b9YXvkvNj3kpaNqjoNeAdzD5QGuJyB3yxN/pmxHriV5jc8Y3DfS4DTqmq7gcfdq+p/D2lrdpE1jvy1mLwCsEOSwW33Z7T89UKaoRJPA36J5gKbYe3sTfNvxHeSXAG8Ddi7Hc81V/F3LsO/hwXfK8k9aAqs1VX1lyN8lqlgkdW/uyTZcuCxOc0ppBuBn7Tn6W/vgk/yy0me3Y5TuImmh+S2dttvDQy2vJrmB3MbcArw4CQvTLJ5khcAuwOfGBLTacCTga2qah3NGIb9aMZzfWPIa35IczXdptqm/Sw/SbID8NoF9n9Ukue239eRNN/FGSO2M+d3O1vba/hh4E1Jtk6yL02C+48hLzkJeFmS3duE86c0//CM9F5J7po7LgzYov17mK/QlCbJW4Gnp70wZpb3Ay9tfxt3Y+B3V1W30fw23tD2CO0GHDLw2k/Q5K/fTnKX9vHoJA8dEsdXaAqevYGvt8MpdqYZB/WlIa/5IfCA9oBtU4ycV1r3AV7VfpbfohmHesqI7dwEXAXcjWYs2TCfoinC9mwff06Tv/dsv/PZPgLcI8lL2h6z59Gc7fjyQu+VZFuaoSVfrqqjRvgcU8Miq3+n0Pw4Zx5voElWWwFX0hQOnx7YfzOao6bLgB/THJ29ot32aOBrSX5Kc+Xaq6vqorYn5Vnt666iOa34rKq6cq6A2sHZP6UdIFpV19IM0vzykB8nwAnA7m13/kcX9Q003gjsRTNO6ZM0SXc+H6M5bXo1zRV6z23HZy3krQz/bufyinb/HwHvBf73zBi4JPdPczXS/eH2AbR/SzOm4eL28fpR3qt1Ac3fwA40CetGNu6BlCZSO5byJGCjCUir6lM0v73P0wyO//ysXY6g6Zm5gubA4700xQTtGKdnAAfR5L0raKYRuCtzaA9ozgbOq6qb29VfBS6uqh8NCf8D7X+vSnL2Ah91Lm9lcXnlazSD16+kGb/1vBHHip1Ek1cuBb7DPAeW7fjWK2YeNLn1lvY5cPuE0r/a7v9j4Nk0g+yvoZmO5sCqunKE9/oNmn9/Dm3f86eDuXGaZcPTwtLkS/IG4EFV9eK+Y5G09JL8DXDfqnrJgjsvM0leCvxuVT2+71jUPXuyJEm9SjMP1iPS2Bt4Gc3pK2lZG6nISrJfmgng1ibZ6Hxr+8M4ut1+bpK9Bra9pr3S7dtJ3pshk1FKUhfMX8vCNjRDBK6nGb/1DzhjuO4EFjxd2F458D2aSeTWAWcCB7dzmczscwDw+8ABNIML31ZVj2kHMJ8O7F5VN6aZOfyUqnpHFx9GkgaZvyT1aZSerL2BtVV1YTuI8GSaq6IGHQicVI0zaOYH2b7dtjmwVXsV2N0Y7TJVSVoK5i9Jvdl8hH12YMOJ4dbRHO0ttM8OVbUmyd8D/0NzpdRnquozczWS5v53hwFsvfXWj9ptt93m2k3SndBZZ511ZVWt7OCtzV+SOjcsh41SZM01T8/sc4xz7tPOFXQgzf3jfgJ8IMmLq+pdG+3c3P/ueIBVq1bVmjVrRghN0p1Bktl3JFiyt55jnflL0pIalsNGOV24jg1n351rZu1h+zwNuKiq1rdzGH2Y5obGkjQO5i9JvRmlyDoT2DXJLkm2oJkQbvWsfVYDh7RX6ewDXFNVl9N0s+/TzuIb4KnA+UsYvyTNx/wlqTcLni6sqluTHEEzA/UK4MSqOi/J4e3242hmLT+AZibfG4BD221fS/JBmtl3b6WZhv/4Lj6IJM1m/pLUp4mc8d0xDdJ0SXJWVa3qO46lYP6Sps+wHOaM75IkSR2wyJIkSeqARZYkSVIHLLIkSZI6YJElSZLUAYssSZKkDoxyWx1Jv7C57tzSlcmblkWSppE9WZIkSR2wyJIkSeqARZYkSVIHLLIkSZI6YJElSZLUAYssSZKkDlhkSZIkdcAiS5IkqQMWWZIkSR2wyJIkSeqARZYkSVIHRiqykuyX5IIka5McNcf2JDm63X5ukr3a9Q9Jcs7A49okRy7xZ5Ckocxf0i8qY3zcuSx4g+gkK4BjgKcD64Azk6yuqu8M7LY/sGv7eAxwLPCYqroA2HPgfS4FPrKUH0CShjF/SerTKD1ZewNrq+rCqroZOBk4cNY+BwInVeMMYLsk28/a56nA96vq4l84akkajflLUm9GKbJ2AC4ZWF7XrlvsPgcB711sgJL0CzB/SerNKEXWXCdJazH7JNkCeDbwgaGNJIclWZNkzfr160cIS5IWZP6S1JtRiqx1wE4DyzsCly1yn/2Bs6vqh8Maqarjq2pVVa1auXLlCGFJ0oLMX5J6M0qRdSawa5Jd2iO6g4DVs/ZZDRzSXqWzD3BNVV0+sP1g7GqXNH7mL0m9WfDqwqq6NckRwKnACuDEqjovyeHt9uOAU4ADgLXADcChM69PcjeaK3tevvThS9Jw5i9JfVqwyAKoqlNoEtHguuMGnhfwyiGvvQG41y8QoyRtMvOXpL4447skSVIHLLIkSZI6YJElSZLUAYssSZKkDlhkSZIkdcAiS5IkqQMWWZIkSR2wyJIkSeqARZYkSVIHLLIkSZI6YJElSZLUAYssSZKkDlhkSZIkdcAiS5IkqQMWWZIkSR2wyJIkSeqARZYkSVIHLLIkSZI6YJElSZLUgZGKrCT7JbkgydokR82xPUmObrefm2SvgW3bJflgku8mOT/JY5fyA0jSfMxfkvqyYJGVZAVwDLA/sDtwcJLdZ+22P7Br+zgMOHZg29uAT1fVbsAewPlLELckLcj8JalPo/Rk7Q2sraoLq+pm4GTgwFn7HAicVI0zgO2SbJ9kW+AJwAkAVXVzVf1k6cKXpHmZvyT1ZpQiawfgkoHlde26UfZ5ILAeeHuSbyT59yRbz9VIksOSrEmyZv369SN/AEmah/lLUm9GKbIyx7oacZ/Ngb2AY6vqkcD1wEZjIgCq6viqWlVVq1auXDlCWJK0IPOXpN6MUmStA3YaWN4RuGzEfdYB66rqa+36D9IkLUkaB/OXpN6MUmSdCeyaZJckWwAHAatn7bMaOKS9Smcf4JqquryqrgAuSfKQdr+nAt9ZquAlaQHmL0m92XyhHarq1iRHAKcCK4ATq+q8JIe3248DTgEOANYCNwCHDrzF7wPvbhPchbO2SVJnzF+S+pSq2cMT+rdq1apas2ZN32FIS2iuYT9dmbzf9EKSnFVVq/qOYymYv3TnY/5ayLAc5ozvkiRJHbDIkiRJ6oBFliRJUgcssiRJkjpgkSVJktQBiyxJkqQOWGRJkiR1wCJLkiSpAxZZkiRJHbDIkiRJ6oBFliRJUgcssiRJkjpgkSVJktQBiyxJkqQOWGRJkiR1wCJLkiSpAxZZkiRJHbDIkiRJ6sBIRVaS/ZJckGRtkqPm2J4kR7fbz02y18C2HyT5VpJzkqxZyuAlaSHmL0l92XyhHZKsAI4Bng6sA85MsrqqvjOw2/7Aru3jMcCx7X9nPLmqrlyyqCVpBOYvSX0apSdrb2BtVV1YVTcDJwMHztrnQOCkapwBbJdk+yWOVZIWy/wlqTejFFk7AJcMLK9r1426TwGfSXJWksOGNZLksCRrkqxZv379CGFJ0oLMX5J6M0qRlTnW1SL22beq9qLpkn9lkifM1UhVHV9Vq6pq1cqVK0cIS5IWZP6S1JtRiqx1wE4DyzsCl426T1XN/PdHwEdouu8laRzMX5J6M0qRdSawa5JdkmwBHASsnrXPauCQ9iqdfYBrquryJFsn2QYgydbAM4BvL2H8kjQf85ek3ix4dWFV3ZrkCOBUYAVwYlWdl+TwdvtxwCnAAcBa4Abg0Pblvwx8JMlMW++pqk8v+aeQpDmYvyT1KVWzhyf0b9WqVbVmjVPS6M5krmE/XZm83/RCkpxVVav6jmMpmL9052P+WsiwHOaM75IkSR2wyJIkSeqARZYkSVIHLLIkSZI6YJElSZLUAYssSZKkDlhkSZIkdcAiS5IkqQMWWZIkSR2wyJIkSeqARZYkSVIHLLIkSZI6YJElSZLUAYssSZKkDlhkSZIkdcAiS5IkqQMWWZIkSR2wyJIkSerASEVWkv2SXJBkbZKj5tieJEe3289Nstes7SuSfCPJJ5YqcEkahflLUl8WLLKSrACOAfYHdgcOTrL7rN32B3ZtH4cBx87a/mrg/F84WklaBPOXpD6N0pO1N7C2qi6sqpuBk4EDZ+1zIHBSNc4AtkuyPUCSHYFnAv++hHFL0ijMX5J6M0qRtQNwycDyunbdqPu8Ffgj4OfzNZLksCRrkqxZv379CGFJ0oLMX5J6M0qRlTnW1Sj7JHkW8KOqOmuhRqrq+KpaVVWrVq5cOUJYkrQg85ek3oxSZK0DdhpY3hG4bMR99gWeneQHNN30T0nyrk2OVpIWx/wlqTejFFlnArsm2SXJFsBBwOpZ+6wGDmmv0tkHuKaqLq+qP66qHavqAe3rPl9VL17KDyBJ8zB/SerN5gvtUFW3JjkCOBVYAZxYVeclObzdfhxwCnAAsBa4ATi0u5AlaTTmL0l9StXs4Qn9W7VqVa1Zs6bvMKQlNNewn65M3m96IUnOqqpVfcexFMxfuvMxfy1kWA5zxndJkqQOWGRJkiR1wCJLkiSpAxZZkiRJHbDIkiRJ6oBFliRJUgcssiRJkjpgkSVJktQBiyxJkqQOWGRJkiR1wCJLkiSpAxZZkiRJHbDIkiRJ6oBFliRJUgcssiRJkjpgkSVJktQBiyxJkqQOWGRJkiR1YKQiK8l+SS5IsjbJUXNsT5Kj2+3nJtmrXb9lkq8n+WaS85K8cak/gCTNx/wlqS8LFllJVgDHAPsDuwMHJ9l91m77A7u2j8OAY9v1NwFPqao9gD2B/ZLsszShS9L8zF+S+jRKT9bewNqqurCqbgZOBg6ctc+BwEnVOAPYLsn27fJP233u0j5qqYKXpAWYvyT1ZpQiawfgkoHlde26kfZJsiLJOcCPgM9W1dfmaiTJYUnWJFmzfv36EcOXpHmZvyT1ZpQiK3Osm300N3SfqrqtqvYEdgT2TvLwuRqpquOralVVrVq5cuUIYUnSgsxfknozSpG1DthpYHlH4LLF7lNVPwG+COy32CAlaROZvyT1ZpQi60xg1yS7JNkCOAhYPWuf1cAh7VU6+wDXVNXlSVYm2Q4gyVbA04DvLl34kjQv85ek3my+0A5VdWuSI4BTgRXAiVV1XpLD2+3HAacABwBrgRuAQ9uXbw+8s73CZzPg/VX1iaX/GJK0MfOXpD6lavIullm1alWtWbOm7zCkJTTXsJ+uTN5veiFJzqqqVX3HsRTMX7rzMX8tZFgOc8Z3SZKkDlhkSZIkdcAiS5IkqQMWWZIkSR2wyJIkSerAglM4SJK6kYzzqi2YxKvJpTsze7IkSZI6YJElSZLUgWV/unCc3e12tUuSpFHZkyVJktQBiyxJkqQOWGRJkiR1wCJLkiSpAxZZkiRJHbDIkiRJ6oBFliRJUgcssiRJkjpgkSVJktSBkYqsJPsluSDJ2iRHzbE9SY5ut5+bZK92/U5JvpDk/CTnJXn1Un8ASZqP+UvLVcb4UDcWLLKSrACOAfYHdgcOTrL7rN32B3ZtH4cBx7brbwX+sKoeCuwDvHKO10qdMUlNN/OXpD6N0pO1N7C2qi6sqpuBk4EDZ+1zIHBSNc4AtkuyfVVdXlVnA1TVdcD5wA5LGL8kzcf8Jak3oxRZOwCXDCyvY+NEs+A+SR4APBL42qKjlKRNY/6S1JtRiqy5zoTUYvZJcnfgQ8CRVXXtnI0khyVZk2TN+vXrRwhLkhZk/pLUm1GKrHXATgPLOwKXjbpPkrvQJKh3V9WHhzVSVcdX1aqqWrVy5cpRYpekhZi/JPVmlCLrTGDXJLsk2QI4CFg9a5/VwCHtVTr7ANdU1eVJApwAnF9Vb1nSyCVpYeYvSb3ZfKEdqurWJEcApwIrgBOr6rwkh7fbjwNOAQ4A1gI3AIe2L98X+G3gW0nOade9rqpOWdJPIUlzMH9J6tOCRRZAm1ROmbXuuIHnBbxyjtedjle3S+qR+UtSX5zxXZIkqQMWWZIkSR2wyJIkSeqARZYkSVIHLLIkSZI6YJElSZLUAYssSZKkDow0T5Yk6U4sY54OrGbfPlK6c7InS5IkqQMWWZIkSR2wyJIkSeqAY7KWyjjHNDieQZKkiWdPliRJUgcssiRJkjpgkSVJktQBiyxJkqQOWGRJkiR1wCJLkiSpAyMVWUn2S3JBkrVJjppje5Ic3W4/N8leA9tOTPKjJN9eysAlaRTmL0l9WbDISrICOAbYH9gdODjJ7rN22x/YtX0cBhw7sO0dwH5LEawkLYb5S1KfRunJ2htYW1UXVtXNwMnAgbP2ORA4qRpnANsl2R6gqr4E/Hgpg5akEZm/JPVmlCJrB+CSgeV17brF7iNJ42b+ktSbUYqsue4XM/u+LqPsM38jyWFJ1iRZs379+sW8VJKGMX9J6s0oRdY6YKeB5R2ByzZhn3lV1fFVtaqqVq1cuXIxL5WkYcxfknozSpF1JrBrkl2SbAEcBKyetc9q4JD2Kp19gGuq6vIljlWSFsv8Jak3CxZZVXUrcARwKnA+8P6qOi/J4UkOb3c7BbgQWAv8G/CKmdcneS/wVeAhSdYledkSfwZJmpP5S1KfUrWooQdjsWrVqlqzZs1I+yZzDafoxrzf1RjjYAL/n02qMf5fWWAQz+REMomSnFVVq/qOYylMav6CeXLYmOMwh41mcrLG5EQyqYblMGd8lyRJ6oBFliRJUgcssiRJkjqwed8BSJIkLeg9Yxwb9sKlGRtmT5YkSVIH7MmSpskyPBKUpOXKnixJkqQOWGRJkiR1wCJLkiSpAxZZkiRJHbDIkiRJ6oBXF0qSJkLeOMZ70b7eq1/VPXuyJEmSOmCRJUmS1AFPF97J2N0uSdJksCdLkiSpAxZZkiRJHfB0oSRJAzLGW3yWoy7u1OzJkiRJ6sBIRVaS/ZJckGRtkqPm2J4kR7fbz02y16ivlaQumb8k9WXBIivJCuAYYH9gd+DgJLvP2m1/YNf2cRhw7CJeqzuhZHwPaRjzl6Q+jdKTtTewtqourKqbgZOBA2ftcyBwUjXOALZLsv2Ir5Wkrpi/JPVmlIHvOwCXDCyvAx4zwj47jPhaAJIcRnMUCfDTJBeMENsv4t7AlYt5QbrpNll0HB103yw+BiBvmJA4lv5/y6bFseRhbFocHUSyaXG8aFFx7Lzo9x+N+WtABzls0/42JiCODvLXpsXRTW/84uPoJIxN+fvo/28DWGz+giE5bJQia66WZl8PMWyfUV7brKw6Hjh+hHiWRJI1VbVqXO1NchyTEINxGEdHzF/GYRxTHEffMYxSZK0DdhpY3hG4bMR9thjhtZLUFfOXpN6MMibrTGDXJLsk2QI4CFg9a5/VwCHtVTr7ANdU1eUjvlaSumL+ktSbBXuyqurWJEcApwIrgBOr6rwkh7fbjwNOAQ4A1gI3AIfO99pOPsnija1rfwGTEMckxADGMZtx/ILMX50zjg0Zx4YmIY5eY0g53awkSdKSc8Z3SZKkDlhkSZIkdcAiS5IkqQNTWWQl2brn9h+f5ND2+coku/QZj6Tlw/wlLR9TVWQleVyS7wDnt8t7JPmXMcfweuD/An/crroL8K5xxjAJkmyZ5Mgk/5zk5UlGmbNt6iTZN8kxPbX72STfS3JhkouSXDjuOHQH89fkMH+Nxvw12mSkdyb/CPwa7Vw3VfXNJE8Ycwy/ATwSOLuN4bIk24w5BgCSXMfGM1hfA6wB/rCquvyjfCdwC/Bf3HED3ld32N6ykWRP4IXA84GLgA/3EMYJwGuAs4DbemhfGzN/DTB/TSbz14amrciiqi6Zdf+ucf8PuLmqKklB713/b6GZwfo9NLcQOQi4L3ABcCLwpA7b3r2q/hdAkhOAr3fY1qIl2beqvjzG9h5M8/0fDFwFvI9mipUnjyuGWa6pqk/11LaGMH9twPw1j3HmMPPXcNNWZF2S5HFAtTM4v4q2632M3p/kX4Htkvwe8DvAv405hhn7VdXgDW+PT3JGVb0pyes6bvuWmSftpI8dN7exJCtojrZ2AD5dVd9O8izgdcBWNEfs4/JdmqPiX6+qtW18rxlj+7Rt7tU+/UKSv6M5Cr1pZntVnT3umHQ789eGpjp/wUTlMPPXENNWZB0OvI3mD3Id8BngleNqPM0v8X3AbsC1wEOAP6+qz44rhll+nuT5wAfb5ecNbOt6lto9klzLHTfh3Wpguapq247bh6ZLeSeao9Cjk1wMPBY4qqo+Oob2B/0mzZHgF5J8GjiZDm5HP4J/mLU8eGPVAp4yxli0IfPXhqY9f8Hk5DDz1xBTM+N7W/G/s6pe3HMcZ1XVo/qMYUaSB9Ik7cfS/AGeQXMe+1LgUVV1eo/hdS7Jt4FHVNXPk2wJXAk8qKqu6DGmrYHn0HS7P4Vm7MdHquozfcWk/pm/Njbt+QsmL4eZvzY2NVcXVtVtwMq2m71PZyR5dM8xAFBVF1bVr1fVvatqZft8bVXdOK4EleTJSY5I8sokTxpHmwNurqqfA1TVz4Dv9VxgrQQeCnyyqp4F7AicAxzVQyx/lWS7geV7JPmLccehhvlrY+YvYIJymPlrSCzT0pMF0I4l2Ivm6pzrZ9ZX1VvGGMN3aLrZf9DGMNO9/IhxxTAQy0rg94AHMHDquKp+Zwxt70BzvvxnNFeAhOb/zVbAb1TVpWOI4QaamwLTtv8r7fLY/58k+V3gr4DvA7sAh1XV6nG1P0c836iqR85ad3ZV7TXsNeqW+WujWKY6f7VxTEQOM38NN21jsi5rH5sBvVx2THO576T4GM1gxc8x/quU/hk4tqreMbgyySHAvwAHjiGGh46hjVEdCTysqta3p0HeTXupfk9WJLlrVd0EkGQr4K49xiPz12zTnr9gcnLYkZi/5jRVPVkz2nldqqp+2lP7ewC/2i7+V1V9s6c4zqmqPXtq+4Kqeshit3UUyy7Aw2jGdZzf8fw6w2LY4Cir716jJH8EPBt4O8338jvA6qr6275iUsP8dXsc5q872uw1h5m/hpuqnqwkDwf+A7hnu3wlcEhVnTfGGF5N08U9M0Hbu5IcX1X/NK4YBnwiyQFVdUoPba+Ya2WSzYZtW2pJtgX+neYKlHNoutj3SHIW8LKqunYccbR2THL0sOWqetW4AmmvInsvcC7wNJrv5c1Vdeq4YtDGzF8bmer81bY3KTnM/DUsnmnqyUryFeBPquoL7fKTgL+qqseNMYZzgcdW1fXt8tbAV3sa03AdsDXNPCK3MMbLj5O8tW37yFnfxT8CPxvHjzLJO2jGlrxpZvBo+wP9M5ordA7pOoaBWF4y3/aqeue4YoHJuopMDfPXRrFMdf5q23wHE5DDzF/DTVVPFrD1TIICqKovZvwzFocNxw/cRj/ziVBVfY3rAHgtzUDJi9PM7VLAzjSX/HY9keCMfavqpYMrqjnqeFOS/x5TDDPtjjUJjeCMJI+uqjP7DkS3M38NMH8BE5LDzF/DTVuRdWGSP6Ppcgd4Mc29lcbp7cDXknykXX4OzYRyY5Nkt6r6bu6YHXcDNZ5ZcfekuS3GnwMPAp4MPAvYArg78OMxxNDPNM1zSPJ44IFVdVK7/EHa00LAX1TV58cc0pOBl7f/gPR6FZluZ/7C/DXLROQw89dw03a68B7AG4HHt6u+BLyxqq4ecxx7tTEE+FJVfWPM7R9fVYcl+cIcm6uqOp8VN8nZwNOq6sdpbnJ7MvD7NMnroVX1vPlev0QxvJPmkuM318APof2H7MFV9dtdxzDQ5n8Cv19V32mXvwW8lOaUxOuqar9xxdK2v/Nc66vq4nHGoTuYv25v3/x1RxwTkcPMX/PEMk1F1iRIsg9wXlVd1y5vQ3Oz0a/1EMuW1UxgN++6jtr+ZlXt0T4/BlhfVW9ol8dy1VA7aPQEmvltzqHp8n8k8A2aQaPXdB3DQCxnVtWjB5Y/XFXPbZ9/uar2HVcss+K6D7DlzHJV/U8fcWgymL9ub6f3/NW2NRE5zPw13NTM+A6Q5LPZeBbYcV9xcCwweOn19e26PnxlxHVdWJFk5nT1U4HB7uSxnMauqmur6reAZwDvAE4CntEehR46jhgGbDcrtucOLP7yeEOBJM9ux3RcBJxGM7h2Iu5qP63MXxuZ6vwFE5XDtpsVl/mrNW1jsu5dVT+ZWaiqq9tKd5wy2K1bzT2nxvr/Icl9aW4yu1WSR3LHef1tgbuNKYz3Aqe1l6HfSDOpIEkeBIytBwmgqr5P0+U+6A+At44xjO8meWZVfXJwZZJnAReMMY4Zbwb2AT5XVY9M8mSa+5GpP+YvzF9zmYAcZv4aYtqKrJ8nuf9Ml2F73nbc50svTPIq7jj6ewUw7skvf43mfPmONIM3Z1zHmK6Mqaq/bM/jbw98ZiBxb0YztqFv4x5Q+hrgk0meB8wM3H0U8DiaAbXjdktVXZVksySbVdUXkvxND3HoDuavhvlrNOPMYeavIaZqTFaS/YDjaboPAZ5Ac4+lsXW5t0eeR9PcoRyaW0IcWVU/GlcMA7H8ZlV9aNztLgdJ/qeq7j/G9h4E3Bd4MM3MzQDn0dyH7NL2SHVsknyO5sqxvwbuBfwIeHSNcU4mbcj8tVEs5q95jDOHmb/miWWaiiyAJPem6UYEOKOqruwznr4leSbNj2JwcOCb+otofNJMZjjXDyDAVlU1tp7eJJ+guQrn3FnrVwGvr6pfH1csbbtb05wG2Qx4EfBLwLur6qpxxqENmb82NM35CyYnh5m/hpuKge9Jdk7ySwBtUroeeDpwSJItxhTD7yXZtX2eJCcmuSbJuRky38sYYjoOeAFN93aA36KZUG8qVNU2VbXtHI9txllgtR4wO0G1Ma4BHjDmWKhmFuudgCdVM9HgvwM3jzsOmb/miWmq8xdMVA4zfw0xFUUW8H6a+TpIsifwAeB/gD1o7pg+Dq+mucIBmgF4ewAPpBmc+LYxxTDb46q57cLVVfVG4LE0f5gavy3n2bbV2KJoJfk94IPAv7ardgA+Ou44BJi/hjF/TQ7z1xDTUmRtVVWXtc9fDJxYVf9Ac4nr3mOK4daquqV9/izgpKq6qqo+R5tAe3Bj+98bktyP5v5fu/QUy7Q7s00MG0jyMuCsHuJ5JbAvcC1AVf03MO4r2dQwf83N/DU5zF9DTMvVhYNXWTwF+GO4/fLjccXw8yTbA1fTzKvylwPbxl7ptz7RzrvzdzRXhBRNt6rG70jgI0lexB1JaRXNbTp+o4d4bqqqm2d+H+1l+tM1gHNymL/mZv6aHEdi/prTtBRZn0/yfuBy4B60E8e1SWNc52n/HFgDrABWV9V5bQxPZPyXQANQVW9un36oHbi4JXBrH7FMu6r6IfC4dj6Xh7erP1njv+fXjNOSvI5mLqKn01yq//GeYpl25q85mL8mh/lruKm4ujBNOfsCmjlN3l9Vl7brHwncZ1yXQLfV9DY1cK+x9iqIVNVP2+WnV9VnxxDLDjTfx7ltxX8fmqORl1bV/bpuX5MtyWbAy2hmkg5wKvDvNQ0JY8KYv+aMxfyloSYpf01FkTWqJF+tqsf2HMPZVdXp1TpJjgT+hGYOk7vSDFx9C80tGf62qi7vsn0tL0nuCew419VDmhzmL/OXNtZ3/pqW04Wjmu8KiXEZxyCLw4CHVHMH+fvTJKsnVNUZY2hby0CSLwLPpskR5wDrk5xWVX/QZ1yal/lLYrLy17RcXTiqSejWG0cMP6uqH8PtdyX/nglKs/xSVV0LPBd4e1U9CnhazzFpfuYvqTEx+cuerOm0Y5KjB5bvM7hcVa/qISZNls3bgdXPpzk1I00K85cWMjH5yyJrQ+O+KXDTaPKYqvpau/iDMTT52lnLfcxjosn2JprBol+uqjOTPBD4755j0vzMX1JjYvLXVAx8T7JbVX23fX7XqrppYNs+M13NSR5eVd/uIb6x3ox4VEn+qaom5Y7y0lQyf20a85cmwbSMyXrPwPOvztp2+20p+khQrV6OQEewb98BqB9JHpzkP5N8u11+RJI/7TuuKWX+2jTmryk1SflrWoqsDHk+13If7vzdiVpu/o1mZvFbANrLnw/qNaLpZf6SFmdi8te0jMmqIc/nWu5Eko8PaSvAvcYRg7QId6uqr8+6bYuzaffD/CUtzsTkr2kpsmauRgkbXpkSmrtzj8Pfb+K2Pk3CUbL6cWWSX6H9hzXJ82hu66LxM39tGvPX9JqY/DUtRdbg1ShrZm2bvdyVi9o5XSbGCANl3za2YDRpXgkcD+yW5FLgIuBF/YY0tcxfczB/aR4Tk7+m4urC+STZuaouHkM7t99uIsmHquo3u25zhJhOp7lL+juA91TVT3oNSBOnvTfdZsCNwAuq6t09h6QB5i/zl4abhPw1LQPfSfLYJM9rbyQ6c7XBe4DTxxXCwPMHjqnNeVXV42mq+52ANUne096xXFMqybZJ/jjJP7d/CzcAL6G5dcnz+41uepm/Nmb+0myTmL+moicryd8Bz6K5h9GDgE8ArwD+CvjXqvrZGGIYPBLs/Caqi5FkBfAc4GjgWpqE+rqq+nCfcWn8knwMuJpmqoCnAveg6S14dVWd02NoU8v8NT/zl2ZMYv6aliLrO8BeVfWzJPcALgMeUVVjmwE2yW3A9TQJYCuaCpt2uapq23HFMhDTI4BDgWcCnwVOqKqzk9wP+GpV7TzumNSvJN+qqv/VPl8BXAncv6qu6zey6WX+GhqT+UsbmMT8NS0D32+cOdqrqquTXDDOBNW2u2Kc7Y3on2nmE3ldVd04s7KqLnPiyal1y8yTqrotyUUWWL0zf83N/KXZJi5/TUtP1k+ALw2sekK7PHMU9uwxxPCUqvp8+3yXqrpoYNtz++jaTnJkVb111rpXV5VX5UypgR4L2LDXorcei2ln/hoak/lLG5jE/DUtRdYT51g988FTVaeNIYahYxr6GuMwV7tJvlFVjxx3LJLmZv5aOKaBdeYvTZRpOV24HbBjVR0DkOTrwEqaRPV/xxTDxNwaI8nBwAuBXZKsHti0DXDVOGORtKDtMH/d0Zj5S8vItBRZf8SG9y3aAlgFbA28HfjAGGLo/dYYA75CM/vtvYF/GFh/HXDumGORND/z14bMX1o2pqXI2qKqLhlYPr2qrgKuaicrG4cHtkddGXhOu7zLmGIAoJ288GLgseNsV9ImMX8NMH9pOZmWMVlrq+pBQ7Z9v6p+ZQwxzDWu4nbjGFcxEMvpVfX4JNex4VGog5ulCWP+2igW85eWjWkpst4NfLGq/m3W+pcDT6qqg8cYy5Y0EwoW8P1xTCQoafkyf0nL17QUWfcBPgrcBJzdrn4UcFfgOVX1wzHEsDnNDM2/Q9PVvRmwI82Yij+pqlvmeXlXMf0KsK6qbkryJOARwEneA0yaHOavoTGZvzTxpqLImpHkKcDD2sXzZuZ9GVPb/0hz9ctrZiZHS7It8Pc0kw2+elyxDMR0Ds0A2gcApwKrgYdU1QHjjkXS/MxfG8V0DuYvTbipKrL6lOS/gQfXrC+8nfr/u1W1aw8xnV1VeyV5LfCzqvon55mRNJv5S9o0m/UdwBSp2QmqXXkb478EesYt7ZwzL6G56SzAXXqKRdLkMn9Jm8Aia3y+k+SQ2SuTvBj4bg/xQHNz1ccCf1lVFyXZBXhXT7FImlzmL2kTeLpwTJLsBHwQuBE4i+bo79E091b6jaq6dMzxrADeWVUvHme7kpYf85e0aaZlMtJJ8LF2/MBTgd1p5nT5VFX9Zx/BtHcoX5lki6q6uY8YJC0b5i9pE1hkjU8A2qTUS2Kaww+AL7ezN8/cuZyqektvEUmaROYvaRNYZI3PyiR/MGxjT4nhsvaxGc3l2ZI0F/OXtAksssZnBXB3xnzH+vlU1RsBkmxdVdcvtL+kqWX+kjaBA9/HZGZOl77jGJTkscAJwN2r6v5J9gBeXlWv6Dk0SRPE/CVtGqdwGJ+JOQIc8Fbg14CrAKrqm8AT+gxI0kQyf0mbwCJrfJ7adwBzqapLZq26rZdAJE0y85e0CRyTNSZV9eO+Y5jDJUkeB1SSLYBXAef3HJOkCWP+kjaNY7KmWJJ7A28DnkZzOuAzwKur6qpeA5OkBZi/tBxYZE2xJCuran3fcUjSYpm/tBw4Jmu6fSXJZ5K8LMl2fQcjSYtg/tLEs8iaYlW1K/CnwMOAs5N8or3hqyRNNPOXlgNPFwq4fXzDW4AXVdWKvuORpFGZvzSp7MmaYkm2TfKSJJ8CvgJcDuzdc1iStCDzl5YDe7KmWJKLgI8C76+qr/YcjiSNzPyl5cAia4olSfkHIGkZMn9pOXAy0imU5K1VdSSwOslGSaqqnj3+qCRpYeYvLScWWdPpP9r//n2vUUjS4pm/tGx4ulCSJKkD9mRNsST7Am8Adqb5WwhQVfXAPuOSpIWYv7Qc2JM1xZJ8F3gNcBYDd6/33l+SJp35S8uBPVnT7Zqq+lTfQUjSJjB/aeLZkzXFkvw1sAL4MHDTzPqqOru3oCRpBOYvLQcWWVMsyRfapzN/BDNjGp7SU0iSNBLzl5YDi6wplOQPZp62/y1gPXB6VV3UT1SStDDzl5YT7104nbZpH3dvH9sAq4BPJTmoz8AkaQHmLy0b9mTpdknuCXyuqvbqOxZJWgzzlyaRPVm6XVX9mDu64CVp2TB/aRJZZOl2SZ4CXN13HJK0WOYvTSLnyZpCSb7FHVfkzLgncBlwyPgjkqTRmL+0nDgmawol2XnWqgKuqqrr+4hHkkZl/tJyYpElSZLUAcdkSZIkdcAiS5IkqQMWWZIkSR2wyJIkSerA/wc7f4ITIvD1gQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['black', 'red', 'green', 'blue', 'cyan', 'yellow', 'orange']\n",
    "\n",
    "lasso = Lasso(alpha = best_alpha_lasso)\n",
    "lasso.fit(scaled_train_X, train_y)\n",
    "\n",
    "ridge = Ridge(alpha = best_alpha_ridge)\n",
    "ridge.fit(scaled_train_X, train_y)\n",
    "\n",
    "plt.subplots(figsize=(10, 4), sharey= True)\n",
    "plt.subplot(121)\n",
    "plt.bar(list(train_X.columns), lasso.coef_, color=colors)\n",
    "plt.ylim([0, 0.08])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Lasso with alpha \" + str(round(best_alpha_lasso, 3)))\n",
    "plt.subplot(122)\n",
    "plt.bar(list(train_X.columns), ridge.coef_, color=colors)\n",
    "plt.ylim([0, 0.08])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Ridge with alpha \" + str(round(best_alpha_ridge, 3)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the regularization parameter is increased or the shirkage factor is increased, the value of coefficents usually go down. \n",
    "Clearly from the plot, coefficent of of CGPA went down as we moved from 0.001 alpha to 4.462 alpha "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso with modified target\n",
      "Lowest MSE =  0.01476731964422993\n",
      "alpha =  0.0018738174228603867\n",
      "\n",
      "Lasso original\n",
      "Lowest MSE =  1.004106835348468 (= exp(MSE) exp taken to bring original and modified in same scale)\n",
      "alpha =  0.001072267222010321\n",
      "--------------------------\n",
      "\n",
      "Ridge with modified target\n",
      "Lowest MSE =  0.014815008775351055\n",
      "alpha =  6.135907273413176\n",
      "\n",
      "Ridge original\n",
      "Lowest MSE =  1.0041265045543144 (= exp(MSE) exp taken to bring original and modified in same scale)\n",
      "alpha =  4.641588833612772\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "exp_y = np.exp(train_y)\n",
    "\n",
    "alphas = 10**np.linspace(6,-6,100)\n",
    "new_best_accruacy_lasso = np.inf\n",
    "new_best_alpha_lasso = None\n",
    "new_best_accruacy_ridge = np.inf\n",
    "new_best_alpha_ridge = None\n",
    "\n",
    "for a in alphas:\n",
    "    lasso = Lasso(alpha = a)\n",
    "    scores = cross_val_score(lasso, scaled_train_X, exp_y, cv = 5, scoring = scorer)\n",
    "    if(np.mean(scores) < new_best_accruacy_lasso):\n",
    "        new_best_accruacy_lasso = np.mean(scores)\n",
    "        new_best_alpha_lasso = a\n",
    "    \n",
    "    ridge = Ridge(alpha = a)\n",
    "    scores = cross_val_score(ridge, scaled_train_X, exp_y, cv = 5, scoring = scorer)\n",
    "    if(np.mean(scores) < new_best_accruacy_ridge):\n",
    "        new_best_accruacy_ridge = np.mean(scores)\n",
    "        new_best_alpha_ridge = a\n",
    "    \n",
    "print(\"Lasso with modified target\")\n",
    "print(\"Lowest MSE = \", new_best_accruacy_lasso)\n",
    "print(\"alpha = \", new_best_alpha_lasso)\n",
    "\n",
    "print(\"\\nLasso original\")\n",
    "print(\"Lowest MSE = \", math.exp(best_accruacy_lasso), \n",
    "      \"(= exp(MSE) exp taken to bring original and modified in same scale)\")\n",
    "print(\"alpha = \", best_alpha_lasso)\n",
    "\n",
    "\n",
    "print('--------------------------')\n",
    "print(\"\\nRidge with modified target\")\n",
    "print(\"Lowest MSE = \", new_best_accruacy_ridge)\n",
    "print(\"alpha = \", new_best_alpha_ridge)\n",
    "\n",
    "print(\"\\nRidge original\")\n",
    "print(\"Lowest MSE = \", math.exp(best_accruacy_ridge), \n",
    "      \"(= exp(MSE) exp taken to bring original and modified in same scale)\")\n",
    "print(\"alpha = \", best_alpha_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the exponential of target has helped in reducing the Mean Square Error. In other words, the predictability of the model imporved by modifying the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "colors = ['black', 'red', 'green', 'blue', 'cyan', 'yellow', 'orange']\n",
    "\n",
    "elastic_net1 = ElasticNet(alpha = 0.001)\n",
    "elastic_net1.fit(scaled_train_X, train_y)\n",
    "\n",
    "elastic_net2 = ElasticNet(alpha = 0.01)\n",
    "elastic_net2.fit(scaled_train_X, train_y)\n",
    "\n",
    "elastic_net3 = ElasticNet(alpha = 0.1)\n",
    "elastic_net3.fit(scaled_train_X, train_y)\n",
    "\n",
    "plt.subplots(figsize=(15, 4), sharey= True)\n",
    "plt.subplot(131)\n",
    "plt.bar(list(train_X.columns), elastic_net1.coef_, color=colors)\n",
    "plt.ylim([0, 0.08])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Elastic Net with alpha 0.001\")\n",
    "plt.subplot(132)\n",
    "plt.bar(list(train_X.columns), elastic_net2.coef_, color=colors)\n",
    "plt.ylim([0, 0.08])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Elastic Net with alpha 0.01\")\n",
    "plt.subplot(133)\n",
    "plt.bar(list(train_X.columns), elastic_net3.coef_, color=colors)\n",
    "plt.ylim([0, 0.08])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Elastic Net with alpha 0.1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As alpha increases, the value of coefficents decreases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All three methods(Lasso, Ridge, and Elastic Net), help in regularizing the Linear Regression. The regularization method is similar for all three methods.\n",
    "\n",
    "**Lasso Regression**<br>\n",
    "Pros - Becasue of cost function in lasso some coefficents are shrunk to zero. This reduces the number of coefficents in Linear Regression. Thus, Regresssion model created through Lasso is usually easier to interpret.<br>\n",
    "Cons - The cost function of Lasso is such that test accuracy is not usually as high as Ridge regression. (This is because some variables are completely removed from the model) Some training accuracy is scarifised in Lasso in lieu of interpretability.<br>\n",
    "<br>\n",
    "**Ridge Regression**<br>\n",
    "Pros - Becasue of cost function in ridge some coefficents tend towards zero. The regularization helps in achieving high test accuracy<br>\n",
    "Cons - Becasue the number of variables usually remain almost same, the interpretability of Ridge Regression is usually lower than Lasso Regression<br>\n",
    "<br>\n",
    "**Elastic Net Regression**<br>\n",
    "Pros - The cost function of elastic net is combination of Lasso and Ridge Regression. Elastic Net is midway between Ridge and Lasso. Elastic Net is not as agressive as Lasso in eliminating the variables.<br>\n",
    "Cons - Computation cost of Lasso is higher than Ridge and Lasso Regression.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy\n",
      "MSE with Linear Regresssion with no regularisation =  0.0038570690453814307\n",
      "MSE with Lasso (alpha =  0.001072267222010321 ) =  0.0038588899424586032\n",
      "MSE with Ridge (alpha =  4.641588833612772 ) =  0.0038611057409614303\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_model_without_reg = LinearRegression()\n",
    "lasso = Lasso(alpha= best_alpha_lasso)\n",
    "ridge = Ridge(alpha= best_alpha_ridge)\n",
    "\n",
    "print('Train set accuracy')\n",
    "\n",
    "linear_model_without_reg.fit(scaled_train_X, train_y)\n",
    "mse = mean_squared_error(train_y, \n",
    "                         linear_model_without_reg.predict(scaled_train_X))\n",
    "print(\"MSE with Linear Regresssion with no regularisation = \", mse)\n",
    "\n",
    "lasso.fit(scaled_train_X, train_y)\n",
    "mse = mean_squared_error(train_y, \n",
    "                         lasso.predict(scaled_train_X))\n",
    "print(\"MSE with Lasso (alpha = \", best_alpha_lasso, \") = \", mse)\n",
    "\n",
    "ridge.fit(scaled_train_X, train_y)\n",
    "mse = mean_squared_error(train_y, \n",
    "                         ridge.predict(scaled_train_X))\n",
    "print(\"MSE with Ridge (alpha = \", best_alpha_ridge, \") = \", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy\n",
      "MSE with Linear Regresssion with no regularisation =  0.005200215496311306\n",
      "R2 with Linear Regresssion with no regularisation =  0.6910288907914794\n",
      "MSE with Lasso (alpha =  0.001072267222010321 ) =  0.005169728551461911\n",
      "R2 with Lasso (alpha =  0.001072267222010321 ) =  0.6928402744107118\n",
      "MSE with Lasso (alpha =  4.641588833612772 ) =  0.0051457349267028775\n",
      "R2 with Lasso (alpha =  4.641588833612772 ) =  0.6942658570353146\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set accuracy\")\n",
    "\n",
    "mse = mean_squared_error(test_y, \n",
    "                         linear_model_without_reg.predict(scaled_test_X))\n",
    "print(\"MSE with Linear Regresssion with no regularisation = \", mse)\n",
    "print(\"R2 with Linear Regresssion with no regularisation = \", linear_model_without_reg.score(scaled_test_X, test_y))\n",
    "\n",
    "mse = mean_squared_error(test_y, \n",
    "                         lasso.predict(scaled_test_X))\n",
    "print(\"MSE with Lasso (alpha = \", best_alpha_lasso, \") = \", mse)\n",
    "print(\"R2 with Lasso (alpha = \", best_alpha_lasso, \") = \", lasso.score(scaled_test_X, test_y))\n",
    "\n",
    "mse = mean_squared_error(test_y, \n",
    "                         ridge.predict(scaled_test_X))\n",
    "print(\"MSE with Ridge (alpha = \", best_alpha_ridge, \") = \", mse)\n",
    "print(\"R2 with Ridge (alpha = \", best_alpha_ridge, \") = \", ridge.score(scaled_test_X, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy\n",
      "MSE with Linear Regresssion with no regularisation =  0.0038570690453814302\n",
      "MSE with Lasso (alpha =  0.001072267222010321 ) =  0.0038732792224167277\n",
      "MSE with Ridge (alpha =  4.641588833612772 ) =  0.003890782794503721\n",
      "\n",
      "\n",
      "Test set accuracy\n",
      "MSE with Linear Regresssion with no regularisation =  0.004526319242200025\n",
      "R2 with Linear Regresssion with no regularisation =  0.7310684763186415\n",
      "MSE with Lasso (alpha =  0.001072267222010321 ) =  0.0045818225212272854\n",
      "R2 with Lasso (alpha =  0.001072267222010321 ) =  0.7277707457346057\n",
      "MSE with Lasso (alpha =  4.641588833612772 ) =  4.706900265862788\n",
      "R2 with Lasso (alpha =  4.641588833612772 ) =  0.7314641213423744\n"
     ]
    }
   ],
   "source": [
    "linear_model_without_reg = LinearRegression()\n",
    "lasso = Lasso(alpha= best_alpha_lasso)\n",
    "ridge = Ridge(alpha= best_alpha_ridge)\n",
    "\n",
    "print('Train set accuracy')\n",
    "\n",
    "linear_model_without_reg.fit(train_X, train_y)\n",
    "mse = mean_squared_error(train_y, \n",
    "                         linear_model_without_reg.predict(train_X))\n",
    "print(\"MSE with Linear Regresssion with no regularisation = \", mse)\n",
    "\n",
    "lasso.fit(train_X, train_y)\n",
    "mse = mean_squared_error(train_y, \n",
    "                         lasso.predict(train_X))\n",
    "print(\"MSE with Lasso (alpha = \", best_alpha_lasso, \") = \", mse)\n",
    "\n",
    "ridge.fit(train_X, train_y)\n",
    "mse = mean_squared_error(train_y, \n",
    "                         ridge.predict(train_X))\n",
    "print(\"MSE with Ridge (alpha = \", best_alpha_ridge, \") = \", mse)\n",
    "\n",
    "print(\"\\n\\nTest set accuracy\")\n",
    "\n",
    "mse = mean_squared_error(test_y, \n",
    "                         linear_model_without_reg.predict(test_X))\n",
    "print(\"MSE with Linear Regresssion with no regularisation = \", mse)\n",
    "print(\"R2 with Linear Regresssion with no regularisation = \", linear_model_without_reg.score(test_X, test_y))\n",
    "\n",
    "mse = mean_squared_error(test_y, \n",
    "                         lasso.predict(test_X))\n",
    "print(\"MSE with Lasso (alpha = \", best_alpha_lasso, \") = \", mse)\n",
    "print(\"R2 with Lasso (alpha = \", best_alpha_lasso, \") = \", lasso.score(test_X, test_y))\n",
    "\n",
    "mse = mean_squared_error(test_y, \n",
    "                         ridge.predict(scaled_test_X))\n",
    "print(\"MSE with Ridge (alpha = \", best_alpha_ridge, \") = \", mse)\n",
    "print(\"R2 with Ridge (alpha = \", best_alpha_ridge, \") = \", ridge.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling has following advantages:<br>\n",
    "1. **Improves fit of the model** - No one variable should dominate over the variables just because of scale. For e.g. - if CGPA variable's scale is changed from 1-10 to percentage 1-100. This kind of abritary change to scale of one variable can lead to different the linear model and can lead to CGPA dominating over other variables. Such inconsistensies can lead to poor fit and thus low test score. \n",
    "2. **Better interpretation of importance of each variable in the model** - If all the variables have been scaled, looking at the absolute coefficients of all variables, we can easily comment which variable is most important for making the prediction. If the variables are not scaled, then coefficents of all variables will depend on feature's important and it's scale. Thus, looking at coeffiecnts of one variable, it will not be clear if the coefficent is large due to scale or it's importance."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MIS 382N - HW1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
